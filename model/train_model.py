import arff
import pandas as pd
import numpy as np
import os
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import copy

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import Perceptron
from sklearn.naive_bayes import GaussianNB
from sklearn.feature_selection import SelectKBest, mutual_info_classif
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# === 1. ƒê∆∞·ªùng d·∫´n ===
BASE_DIR = os.getcwd()
DATA_PATH = os.path.join(BASE_DIR, "data", "phishing.arff")
RESULT_DIR = os.path.join(BASE_DIR, "result")
os.makedirs(RESULT_DIR, exist_ok=True)

# === 2. ƒê·ªçc d·ªØ li·ªáu .arff ===
with open(DATA_PATH, "r") as f:
    data = arff.load(f)

columns = [col[0] for col in data["attributes"]]
df = pd.DataFrame(data["data"], columns=columns).astype(int)

# ‚úÖ Lo·∫°i b·ªè c√°c d√≤ng c√≥ nh√£n "Result = 0" (nghi ng·ªù)
df = df[df["Result"] != 0]

# === 3. T√°ch ƒë·∫∑c tr∆∞ng v√† nh√£n ===
X_raw = df.drop("Result", axis=1)
y_raw = df["Result"]

# === 4. Ti·ªÅn x·ª≠ l√Ω: ch·ªçn ƒë·∫∑c tr∆∞ng, chu·∫©n h√≥a, SMOTE ===
selector = SelectKBest(mutual_info_classif, k=20)
X_selected = selector.fit_transform(X_raw, y_raw)
selected_features = X_raw.columns[selector.get_support()]
X_filtered = pd.DataFrame(X_selected, columns=selected_features)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_filtered)
X_processed = pd.DataFrame(X_scaled, columns=selected_features)

smote = SMOTE(random_state=42)
X_final, y_final = smote.fit_resample(X_processed, y_raw)

# === Bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n tr∆∞·ªõc v√† sau SMOTE ===
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
sns.countplot(x=y_raw, palette="Set1")
plt.title("Tr∆∞·ªõc SMOTE")
plt.xlabel("Label")
plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")

plt.subplot(1, 2, 2)
sns.countplot(x=y_final, palette="Set2")
plt.title("Sau SMOTE")
plt.xlabel("Label")
plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")

plt.suptitle("Ph√¢n b·ªë nh√£n tr∆∞·ªõc v√† sau SMOTE", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.savefig(os.path.join(RESULT_DIR, "label_distribution_comparison.png"))
plt.close()

print("üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n tr∆∞·ªõc/sau SMOTE t·∫°i: result/label_distribution_comparison.png")

# === 5. T√°ch train/test ===
X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)

# === 6. M√¥ h√¨nh v√† ƒë√°nh gi√° ===
models = {
    "DecisionTree": DecisionTreeClassifier(),
    "RandomForest": RandomForestClassifier(n_estimators=100),
    "KNN": KNeighborsClassifier(),
    "Perceptron": Perceptron(),
    "NaiveBayes": GaussianNB(),
}

compare_scores = []
for name, model in models.items():
    print(f"‚è≥ ƒêang x·ª≠ l√Ω m√¥ h√¨nh: {name}")

    model_raw = copy.deepcopy(model)
    model_proc = copy.deepcopy(model)

    try:
        model_raw.fit(X_train_raw, y_train_raw)
        pred_raw = model_raw.predict(X_test_raw)
        acc_raw = accuracy_score(y_test_raw, pred_raw)
        report_raw = classification_report(y_test_raw, pred_raw, output_dict=True)
    except Exception as e:
        print(f"[!] L·ªói khi ch·∫°y m√¥ h√¨nh {name} v·ªõi d·ªØ li·ªáu raw: {e}")
        acc_raw = report_raw = None

    model_proc.fit(X_train, y_train)
    pred_proc = model_proc.predict(X_test)
    acc_proc = accuracy_score(y_test, pred_proc)
    report_proc = classification_report(y_test, pred_proc, output_dict=True)

    compare_scores.append({
        "Model": name,
        "Accuracy (Raw)": acc_raw if acc_raw else 0,
        "Accuracy (Processed)": acc_proc,
        "Precision (Raw)": report_raw["weighted avg"]["precision"] if report_raw else 0,
        "Precision (Processed)": report_proc["weighted avg"]["precision"],
        "Recall (Raw)": report_raw["weighted avg"]["recall"] if report_raw else 0,
        "Recall (Processed)": report_proc["weighted avg"]["recall"],
        "F1 (Raw)": report_raw["weighted avg"]["f1-score"] if report_raw else 0,
        "F1 (Processed)": report_proc["weighted avg"]["f1-score"],
    })

# === 7. V·∫Ω bi·ªÉu ƒë·ªì g·ªôp 4 ch·ªâ s·ªë (Processed data) ===
df_compare = pd.DataFrame(compare_scores)

metrics = ["Accuracy", "Precision", "Recall", "F1"]
bar_width = 0.15
index = np.arange(len(df_compare["Model"]))

fig, ax = plt.subplots(figsize=(14, 7))
for i, metric in enumerate(metrics):
    bars = ax.bar(index + i * bar_width, df_compare[f"{metric} (Processed)"], bar_width, label=metric)
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, yval + 0.003, f"{yval * 100:.2f}%",
                ha='center', va='bottom', fontsize=8)

ax.set_xticks(index + 1.5 * bar_width)
ax.set_xticklabels(df_compare["Model"], rotation=45)
ax.set_ylim(0.5, 1.0)
ax.set_ylabel("Score")
ax.set_title("So s√°nh c√°c ch·ªâ s·ªë (Processed data)")
ax.legend()
plt.tight_layout()
plt.savefig(os.path.join(RESULT_DIR, "all_metrics_combined.png"))
plt.close()
print("üìä ƒê√£ v·∫Ω h√¨nh t·ªïng h·ª£p c√°c ch·ªâ s·ªë t·∫°i: result/all_metrics_combined.png")

# === 8. L∆∞u b·∫£ng t·ªïng h·ª£p ===
df_compare.to_csv(os.path.join(RESULT_DIR, "score_comparison.csv"), index=False)

# === 9. Ghi TXT k·∫øt qu·∫£ ===
txt_path = os.path.join(RESULT_DIR, "score_comparison.txt")
with open(txt_path, "w", encoding="utf-8") as f:
    for row in compare_scores:
        f.write(f"\nüìä Model: {row['Model']}\n")
        f.write(f"  - Accuracy:    {row['Accuracy (Raw)']:.4f} ‚Üí {row['Accuracy (Processed)']:.4f}\n")
        f.write(f"  - Precision:   {row['Precision (Raw)']:.4f} ‚Üí {row['Precision (Processed)']:.4f}\n")
        f.write(f"  - Recall:      {row['Recall (Raw)']:.4f} ‚Üí {row['Recall (Processed)']:.4f}\n")
        f.write(f"  - F1-Score:    {row['F1 (Raw)']:.4f} ‚Üí {row['F1 (Processed)']:.4f}\n")
        f.write("-" * 50 + "\n")

print(f"üìÑ ƒê√£ l∆∞u k·∫øt qu·∫£ chi ti·∫øt t·∫°i: {txt_path}")
# === Bi·ªÉu ƒë·ªì t∆∞∆°ng quan (heatmap) gi·ªØa ƒë·∫∑c tr∆∞ng v√† nh√£n ===
heatmap_df = X_filtered.copy()
heatmap_df["Result"] = y_raw.reset_index(drop=True)

plt.figure(figsize=(14, 10))
corr = heatmap_df.corr()

sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', center=0)
plt.title("Heatmap t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng v√† nh√£n Result")
plt.tight_layout()

# L∆∞u h√¨nh ·∫£nh
plt.savefig(os.path.join(RESULT_DIR, "heatmap_correlation.png"))
plt.close()

print("üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì heatmap t·∫°i: result/heatmap_correlation.png")
# === Boxplot cho 20 ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t ===

# G·ªôp d·ªØ li·ªáu v·ªõi nh√£n ƒë·ªÉ d·ªÖ v·∫Ω
boxplot_df = X_filtered.copy()
boxplot_df["Result"] = y_raw.reset_index(drop=True)

# Chuy·ªÉn d·ªØ li·ªáu sang d·∫°ng "long" ƒë·ªÉ d·ªÖ d√πng seaborn.boxplot
melted_df = pd.melt(boxplot_df, id_vars="Result", var_name="Feature", value_name="Value")

plt.figure(figsize=(16, 10))
sns.boxplot(data=melted_df, x="Feature", y="Value", hue="Result", palette="Set2")
plt.xticks(rotation=45, ha="right")
plt.title("Boxplot ph√¢n ph·ªëi c·ªßa 20 ƒë·∫∑c tr∆∞ng quan tr·ªçng nh·∫•t theo nh√£n Result")
plt.xlabel("ƒê·∫∑c tr∆∞ng")
plt.ylabel("Gi√° tr·ªã (sau chu·∫©n h√≥a)")
plt.legend(title="Result", loc="upper right")
plt.tight_layout()

# L∆∞u h√¨nh
plt.savefig(os.path.join(RESULT_DIR, "boxplot_20_features.png"))
plt.close()

print("üìä ƒê√£ l∆∞u bi·ªÉu ƒë·ªì boxplot c√°c ƒë·∫∑c tr∆∞ng t·∫°i: result/boxplot_20_features.png")
# === 10. L∆∞u d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω ===
processed_df = pd.DataFrame(X_final, columns=selected_features)
processed_df["Result"] = y_final.values

processed_csv_path = os.path.join(RESULT_DIR, "processed_data.csv")
processed_df.to_csv(processed_csv_path, index=False)

print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω t·∫°i: {processed_csv_path}")